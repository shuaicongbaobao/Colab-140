{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuaicongbaobao/Colab-140/blob/main/Rain_Wu_CNN_Brain_Seizure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07xy6XIa1W8w",
        "outputId": "8315e2e8-7bcf-4917-c9a2-287fd8038223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.16)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import gc\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "!pip install timm\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from scipy import signal\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore', category=Warning)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TodRbrLD1g0Z",
        "outputId": "a5482eb4-efe1-424c-f18c-a5cf9dedeaa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Configuration class containing hyperparameters and settings\n",
        "class Config:\n",
        "    seed = 42\n",
        "    image_transform = transforms.Resize((512,512))\n",
        "    batch_size = 16\n",
        "    num_epochs = 5\n",
        "    num_folds = 5\n",
        "\n",
        "# Set the seed for reproducibility across multiple libraries\n",
        "def set_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(Config.seed)\n",
        "\n",
        "# Define the 'Kullback Leibler Divergence' loss function\n",
        "def KL_loss(p,q):\n",
        "    epsilon=10**(-15)\n",
        "    p=torch.clip(p,epsilon,1-epsilon)\n",
        "    q = nn.functional.log_softmax(q,dim=1)\n",
        "    return torch.mean(torch.sum(p*(torch.log(p)-q),dim=1))\n",
        "\n",
        "# Reclaim memory no longer in use.\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6L-xAYe1jER",
        "outputId": "8c8dd8dc-7922-4090-a7d2-3a6daa55a3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Load training data\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/hms-harmful-brain-activity-classification/train.csv\")\n",
        "\n",
        "# Define labels for classification\n",
        "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
        "\n",
        "# Initialize an empty DataFrame for storing features\n",
        "train_feats = pd.DataFrame()\n",
        "\n",
        "# Aggregate votes for each label and merge into train_feats DataFrame\n",
        "for label in labels:\n",
        "    # Group by 'spectrogram_id' and sum the votes for the current label\n",
        "    group = train_df[f'{label}_vote'].groupby(train_df['spectrogram_id']).sum()\n",
        "\n",
        "    # Create a DataFrame from the grouped data\n",
        "    label_vote_sum = pd.DataFrame({'spectrogram_id': group.index, f'{label}_vote_sum': group.values})\n",
        "\n",
        "    # Initialize train_feats with the first label or merge subsequent labels\n",
        "    if label == 'seizure':\n",
        "        train_feats = label_vote_sum\n",
        "    else:\n",
        "        train_feats = train_feats.merge(label_vote_sum, on='spectrogram_id', how='left')\n",
        "\n",
        "# Add a column to sum all votes\n",
        "train_feats['total_vote'] = 0\n",
        "for label in labels:\n",
        "    train_feats['total_vote'] += train_feats[f'{label}_vote_sum']\n",
        "\n",
        "# Calculate and store the normalized vote for each label\n",
        "for label in labels:\n",
        "    train_feats[f'{label}_vote'] = train_feats[f'{label}_vote_sum'] / train_feats['total_vote']\n",
        "\n",
        "# Select relevant columns for the training features\n",
        "choose_cols = ['spectrogram_id']\n",
        "for label in labels:\n",
        "    choose_cols += [f'{label}_vote']\n",
        "train_feats = train_feats[choose_cols]\n",
        "\n",
        "# Add a column with the path to the spectrogram files\n",
        "train_feats['path'] = train_feats['spectrogram_id'].apply(lambda x: \"/content/drive/MyDrive/hms-harmful-brain-activity-classification/train_spectrograms/\" + str(x) + \".parquet\")\n",
        "\n",
        "# Reclaim memory no longer in use.\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yugC7GMU1l2B"
      },
      "outputs": [],
      "source": [
        "def get_batch(paths, batch_size=Config.batch_size):\n",
        "    # Set a small epsilon to avoid division by zero\n",
        "    eps = 1e-6\n",
        "\n",
        "    # Initialize a list to store batch data\n",
        "    batch_data = []\n",
        "\n",
        "    # Iterate over each path in the provided paths\n",
        "    for path in paths:\n",
        "        # Read data from parquet file\n",
        "        data = pd.read_parquet(path[0])\n",
        "\n",
        "        # Fill missing values, remove time column, and transpose\n",
        "        data = data.fillna(-1).values[:, 1:].T\n",
        "\n",
        "        # Clip values and apply logarithmic transformation\n",
        "        data = np.clip(data, np.exp(-6), np.exp(10))\n",
        "        data = np.log(data)\n",
        "\n",
        "        # Normalize the data\n",
        "        data_mean = data.mean(axis=(0, 1))\n",
        "        data_std = data.std(axis=(0, 1))\n",
        "        data = (data - data_mean) / (data_std + eps)\n",
        "\n",
        "        # Convert data to a PyTorch tensor and apply transformations\n",
        "        data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
        "        data = Config.image_transform(data_tensor)\n",
        "\n",
        "        # Append the processed data to the batch_data list\n",
        "        batch_data.append(data)\n",
        "\n",
        "    # Stack all the batch data into a single tensor\n",
        "    batch_data = torch.stack(batch_data)\n",
        "\n",
        "    # Return the batch data\n",
        "    return batch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "8OdfvxI1VTcl",
        "outputId": "c1ebb36b-826f-4a2a-e4f3-0c13ec294a71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
              "0  1628180742           0                       0.0          353733   \n",
              "1  1628180742           1                       6.0          353733   \n",
              "2  1628180742           2                       8.0          353733   \n",
              "3  1628180742           3                      18.0          353733   \n",
              "4  1628180742           4                      24.0          353733   \n",
              "\n",
              "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
              "0                   0                               0.0   127492639   \n",
              "1                   1                               6.0  3887563113   \n",
              "2                   2                               8.0  1142670488   \n",
              "3                   3                              18.0  2718991173   \n",
              "4                   4                              24.0  3080632009   \n",
              "\n",
              "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
              "0       42516          Seizure             3         0         0          0   \n",
              "1       42516          Seizure             3         0         0          0   \n",
              "2       42516          Seizure             3         0         0          0   \n",
              "3       42516          Seizure             3         0         0          0   \n",
              "4       42516          Seizure             3         0         0          0   \n",
              "\n",
              "   grda_vote  other_vote  \n",
              "0          0           0  \n",
              "1          0           0  \n",
              "2          0           0  \n",
              "3          0           0  \n",
              "4          0           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d9d658a-a1b9-4134-8344-31a5159b4d38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eeg_id</th>\n",
              "      <th>eeg_sub_id</th>\n",
              "      <th>eeg_label_offset_seconds</th>\n",
              "      <th>spectrogram_id</th>\n",
              "      <th>spectrogram_sub_id</th>\n",
              "      <th>spectrogram_label_offset_seconds</th>\n",
              "      <th>label_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>expert_consensus</th>\n",
              "      <th>seizure_vote</th>\n",
              "      <th>lpd_vote</th>\n",
              "      <th>gpd_vote</th>\n",
              "      <th>lrda_vote</th>\n",
              "      <th>grda_vote</th>\n",
              "      <th>other_vote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1628180742</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>353733</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127492639</td>\n",
              "      <td>42516</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1628180742</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>353733</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3887563113</td>\n",
              "      <td>42516</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1628180742</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>353733</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1142670488</td>\n",
              "      <td>42516</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1628180742</td>\n",
              "      <td>3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>353733</td>\n",
              "      <td>3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2718991173</td>\n",
              "      <td>42516</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1628180742</td>\n",
              "      <td>4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>353733</td>\n",
              "      <td>4</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3080632009</td>\n",
              "      <td>42516</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d9d658a-a1b9-4134-8344-31a5159b4d38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d9d658a-a1b9-4134-8344-31a5159b4d38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d9d658a-a1b9-4134-8344-31a5159b4d38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8eae6164-1806-45a1-a783-5404c180a5de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8eae6164-1806-45a1-a783-5404c180a5de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8eae6164-1806-45a1-a783-5404c180a5de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ovCdTEjIk8",
        "outputId": "a48d25cb-b081-4873-8ac6-357312934e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training for fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 0 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:23<03:34, 23.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 16 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:42<02:47, 20.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 32 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:02<02:21, 20.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 48 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:23<02:04, 20.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 64 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:46<01:48, 21.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 80 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:01<01:17, 19.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 96 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:24<01:01, 20.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 112 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:45<00:41, 20.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 128 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:02<00:19, 19.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 144 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:23<00:00, 20.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4.40\n",
            "Epoch 1: Test Loss = 69.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 0 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:08,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 16 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:01<00:07,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 32 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:02<00:06,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 48 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:03<00:05,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 64 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:04<00:04,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 80 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:05<00:03,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 96 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:06<00:02,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 112 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:07<00:01,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 128 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:07<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 144 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 0.57\n",
            "Epoch 2: Test Loss = 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 0 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:08,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 16 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:01<00:06,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 32 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:02<00:06,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 48 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:03<00:05,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 64 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:04<00:04,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 80 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:05<00:03,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 96 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:06<00:02,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 112 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:06<00:01,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 128 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:07<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 144 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 0.07\n",
            "Epoch 3: Test Loss = 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 0 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:07,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 16 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:01<00:07,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 32 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:02<00:06,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 48 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:03<00:05,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 64 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:04<00:04,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 80 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:05<00:03,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 96 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:06<00:02,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 112 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:07<00:01,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 128 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:07<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 144 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 0.06\n",
            "Epoch 4: Test Loss = 0.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 0 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:07,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 16 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:01<00:06,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 32 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:02<00:06,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 48 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:03<00:05,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 64 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [00:04<00:04,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 80 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [00:05<00:03,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 96 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [00:06<00:02,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 112 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [00:07<00:01,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 128 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [00:07<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 144 batch's data total 10 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 0.05\n",
            "Epoch 5: Test Loss = 0.07\n",
            "Fold 1 Best Test Loss: 0.07\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "# Determine device availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming train_feats is defined and contains the training features and labels\n",
        "total_idx = np.arange(len(train_feats))\n",
        "np.random.seed(999)\n",
        "np.random.shuffle(total_idx)\n",
        "\n",
        "gc.collect()\n",
        "eeg_dictionary={}\n",
        "eeg_val_dictionary={}\n",
        "eeg_pred_dictionary={}\n",
        "# Cross-validation loop\n",
        "for fold in range(1):\n",
        "    # Split data into train and test sets for this fold\n",
        "    total_idx = total_idx[:3999]\n",
        "    test_idx = total_idx[fold * len(total_idx) // Config.num_folds:(fold + 1) * len(total_idx) // Config.num_folds]\n",
        "    train_idx = np.array([idx for idx in total_idx if idx not in test_idx])\n",
        "\n",
        "    # Initialize EfficientNet-B0 model with pretrained weights\n",
        "    model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=6, in_chans=1)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.005, betas=(0.5, 0.999), weight_decay=0.01)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=Config.num_epochs)\n",
        "\n",
        "    best_test_loss = float('inf')\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    print(f\"Starting training for fold {fold + 1}\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(Config.num_epochs):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        random_num = np.arange(len(train_idx))\n",
        "        np.random.shuffle(random_num)\n",
        "        train_idx = train_idx[random_num]\n",
        "\n",
        "\n",
        "        # Iterate over batches in the training set\n",
        "        for idx in tqdm(range(0, len(train_idx), Config.batch_size)):\n",
        "            optimizer.zero_grad()\n",
        "            train_idx1 = train_idx[idx:idx + Config.batch_size]\n",
        "            train_X1_path = train_feats[['path']].iloc[train_idx1].values\n",
        "            print(f\"loading {idx} batch's data total {len(train_idx) // Config.batch_size} batches\")\n",
        "            train_X1 = get_batch(train_X1_path, batch_size=Config.batch_size)\n",
        "            train_y1 = train_feats[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].iloc[train_idx1].values\n",
        "            train_y1 = torch.Tensor(train_y1)\n",
        "            train_pred = model(train_X1.to(device))\n",
        "            spectrogram_id = train_feats['spectrogram_id'].iloc[train_idx1].values\n",
        "            for i, spectrogram_id1 in enumerate(spectrogram_id):\n",
        "                eeg_dictionary[spectrogram_id1] = train_pred[i,:].detach().cpu().numpy()\n",
        "                eeg_pred_dictionary[spectrogram_id1] = train_y1[i,:].detach().cpu().numpy()\n",
        "            outputs = torch.nn.functional.log_softmax(train_pred,dim=1).to(device)\n",
        "            targets = torch.nn.functional.log_softmax(train_y1, dim=1).to(device)\n",
        "            #oof.append(outputs.numpy())\n",
        "            loss = F.kl_div(outputs, targets, reduction='batchmean',log_target=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        epoch_train_loss = np.mean(train_loss)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        print(f\"Epoch {epoch + 1}: Train Loss = {epoch_train_loss:.2f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluation loop\n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        with torch.no_grad():\n",
        "            for idx in range(0, len(test_idx), Config.batch_size):\n",
        "                test_idx1 = test_idx[idx:idx + Config.batch_size]\n",
        "                test_X1_path = train_feats[['path']].iloc[test_idx1].values\n",
        "                test_X1 = get_batch(test_X1_path, batch_size=Config.batch_size)\n",
        "                test_y1 = train_feats[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].iloc[test_idx1].values\n",
        "                test_y1 = torch.Tensor(test_y1)\n",
        "\n",
        "                test_pred = model(test_X1.to(device))\n",
        "                spectrogram_id = train_feats['spectrogram_id'].iloc[test_idx1].values\n",
        "                for i, spectrogram_id1 in enumerate(spectrogram_id):\n",
        "                    eeg_val_dictionary[spectrogram_id1] = test_pred[i,:].detach().cpu().numpy()\n",
        "                outputs = torch.nn.functional.log_softmax(test_pred,dim=1).to(device)\n",
        "                targets = torch.nn.functional.log_softmax(test_y1, dim=1).to(device)\n",
        "                #oof.append(outputs.numpy())\n",
        "                loss = F.kl_div(outputs, targets, reduction='batchmean',log_target=True)\n",
        "\n",
        "                test_loss.append(loss.item())\n",
        "\n",
        "        epoch_test_loss = np.mean(test_loss)\n",
        "        test_losses.append(epoch_test_loss)\n",
        "        print(f\"Epoch {epoch + 1}: Test Loss = {epoch_test_loss:.2f}\")\n",
        "\n",
        "\n",
        "        # Save the model if it has the best test loss so far\n",
        "        if epoch_test_loss < best_test_loss:\n",
        "            best_test_loss = epoch_test_loss\n",
        "            torch.save(model.state_dict(), f\"efficientnet_b0_fold{fold}.pth\")\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    print(f\"Fold {fold + 1} Best Test Loss: {best_test_loss:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "YfOnjFkCXhSI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame.from_dict({k:{\"y_0\": v[0], \"y_1\": v[1], \"y_2\": v[2], \"y_3\": v[3], \"y_4\": v[4], \"y_5\": v[5]} for k, v in eeg_dictionary.items()},orient=\"index\").to_csv(\"cnn_train.csv\")\n",
        "pd.DataFrame.from_dict({k:{\"y_0\": v[0], \"y_1\": v[1], \"y_2\": v[2], \"y_3\": v[3], \"y_4\": v[4], \"y_5\": v[5]} for k, v in eeg_val_dictionary.items()},orient=\"index\").to_csv(\"cnn_validation.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}